{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'qctrlcore'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [3]\u001B[0m, in \u001B[0;36m<cell line: 25>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# Q-CTRL imports\u001B[39;00m\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mqctrlcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcluster_metrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_best_measurement, intercluster_distance\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mqctrlcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01miq_discriminators\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     27\u001B[0m     create_gradient_boosting_discriminator,\n\u001B[1;32m     28\u001B[0m     create_linear_discriminator,\n\u001B[1;32m     29\u001B[0m     create_random_forest_discriminator,\n\u001B[1;32m     30\u001B[0m )\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mqctrlvisualizer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m get_qctrl_style\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'qctrlcore'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "# Choose to run experiments or to use saved data\n",
    "use_IBM = False\n",
    "if use_IBM:\n",
    "    timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    print(\"Time label for data saved throughout this experiment:\" + timestr)\n",
    "data_folder = Path(\"resources/\")\n",
    "\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Q-CTRL imports\n",
    "from qctrlcore.cluster_metrics import get_best_measurement, intercluster_distance\n",
    "from qctrlcore.iq_discriminators import (\n",
    "    create_gradient_boosting_discriminator,\n",
    "    create_linear_discriminator,\n",
    "    create_random_forest_discriminator,\n",
    ")\n",
    "from qctrlvisualizer import get_qctrl_style\n",
    "from qctrlvisualizer.discriminators import plot_discriminator\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "plt.style.use(get_qctrl_style())\n",
    "\n",
    "# Auxiliary functions\n",
    "def training_test_data(results, test_sample_size):\n",
    "    \"\"\"Randomly separate experiment results in a training and testing set for calibration and use of discriminators.\"\"\"\n",
    "\n",
    "    # Copy results object into a training object and a test object\n",
    "    training_res = copy.deepcopy(results)\n",
    "    test_res = copy.deepcopy(results)\n",
    "\n",
    "    # Randomly select part of the results of for training/test of the discriminator\n",
    "    (\n",
    "        training_res.results[0].data.memory,\n",
    "        test_res.results[0].data.memory,\n",
    "    ) = train_test_split(results.results[0].data.memory, test_size=test_sample_size)\n",
    "    (\n",
    "        training_res.results[1].data.memory,\n",
    "        test_res.results[1].data.memory,\n",
    "    ) = train_test_split(results.results[1].data.memory, test_size=test_sample_size)\n",
    "\n",
    "    return training_res, test_res\n",
    "\n",
    "\n",
    "def calculate_avg_err(rabi_data):\n",
    "    \"\"\"Calculate average value and standard deviation of Rabi data.\"\"\"\n",
    "    rabi_data_avg = []\n",
    "    rabi_data_err = []\n",
    "\n",
    "    # Find average and standard deviation of Rabi data\n",
    "    for i in range(len(rabi_data[0])):\n",
    "        rabi_temp = []\n",
    "        for j in range(len(rabi_data)):\n",
    "            rabi_temp.append(rabi_data[j][i])\n",
    "\n",
    "        # Calculate average of each data point\n",
    "        rabi_data_avg.append(np.average(rabi_temp))\n",
    "\n",
    "        # Calculate standard deviation\n",
    "        rabi_data_err.append(\n",
    "            np.sqrt(\n",
    "                np.sum([(rabi_data_avg[i] - rabi) ** 2 for rabi in rabi_temp])\n",
    "                / len(rabi_temp)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return rabi_data_avg, rabi_data_err\n",
    "\n",
    "\n",
    "def error_gamma(gamma, err_alpha, err_beta, err_f, alpha, beta):\n",
    "    \"\"\"Calculate error in the MLE estimation.\"\"\"\n",
    "    return (1 / (alpha - beta)) * np.sqrt(\n",
    "        gamma**2 * err_alpha**2 + (gamma - 1) ** 2 * err_beta**2 + err_f**2\n",
    "    )\n",
    "\n",
    "\n",
    "def visibility(data):\n",
    "    \"\"\"Calculate the visibility of a sinusoidal signal.\"\"\"\n",
    "    I_max = np.max(data)\n",
    "    I_min = np.min(data)\n",
    "    return round((I_max - I_min) / (I_max + I_min), 2)\n",
    "\n",
    "\n",
    "def ground_excited_experiment(qubit, backend, num_shots, measurement_schedule):\n",
    "    \"\"\"Run an experiment where the ground state is prepared and measured and the excited state is prepared and measured.\"\"\"\n",
    "    # Backend's default settings\n",
    "    backend_defaults = backend.defaults()\n",
    "\n",
    "    # Define default pi-pulse\n",
    "    inst_sched_map = backend_defaults.instruction_schedule_map\n",
    "    pi_default = inst_sched_map.get(\"x\", qubits=backend_config.meas_map[meas_map_idx])\n",
    "\n",
    "    # Create two schedules\n",
    "    # Ground state schedule\n",
    "    gnd_schedule = pulse.Schedule(name=\"cal_00\")\n",
    "    gnd_schedule += measurement_schedule\n",
    "\n",
    "    # Excited state schedule\n",
    "    exc_schedule = pulse.Schedule(name=\"cal_11\")\n",
    "    exc_schedule += pi_default\n",
    "    exc_schedule += measurement_schedule << exc_schedule.duration\n",
    "\n",
    "    # Assemble schedules into an experiment\n",
    "    gnd_exc_program = assemble(\n",
    "        [gnd_schedule, exc_schedule],\n",
    "        backend=backend,\n",
    "        meas_level=1,\n",
    "        meas_return=\"single\",\n",
    "        shots=num_shots,\n",
    "        schedule_los=[{drive_chan: backend_defaults.qubit_freq_est[qubit]}] * 2,\n",
    "    )\n",
    "\n",
    "    # Run\n",
    "    job = backend.run(gnd_exc_program)\n",
    "    job_monitor(job)\n",
    "    gnd_exc_results = job.result(timeout=120)\n",
    "\n",
    "    return gnd_exc_results\n",
    "\n",
    "\n",
    "def train_discriminator(\n",
    "        gnd_exc_results, test_sample, discriminator=create_gradient_boosting_discriminator\n",
    "):\n",
    "    \"\"\"Train a given discriminator to recognize I/Q data corresponding to excited and ground state using the results obtained in a ground/excited state experiment.\"\"\"\n",
    "\n",
    "    # Calibrate discriminator on gnd/exc state experiment\n",
    "    gnd_exc_training_results, gnd_exc_test_results = training_test_data(\n",
    "        gnd_exc_results, test_sample\n",
    "    )\n",
    "\n",
    "    trained_discriminator = []\n",
    "    trained_discriminator.append(\n",
    "        discriminator(gnd_exc_training_results, [qubit], [\"0\", \"1\"])\n",
    "    )\n",
    "\n",
    "    # Collect ground state and excited state data to discriminate\n",
    "    gnd_data = [data[0] for data in gnd_exc_test_results.results[0].data.memory]\n",
    "    exc_data = [data[0] for data in gnd_exc_test_results.results[1].data.memory]\n",
    "\n",
    "    # Store measurement result arrays for inter-cluster distance calculation in post-processing\n",
    "    gnd_exc_data = np.concatenate((np.array(gnd_data), np.array(exc_data)))\n",
    "\n",
    "    # Discriminate ground state data\n",
    "    count_array = list(\n",
    "        map(int, trained_discriminator[0].discriminate(gnd_data))\n",
    "    )  # Turn the string of classified results into a list of integers 0 or 1\n",
    "    probability_exc_gnd = np.sum(count_array) / len(\n",
    "        count_array\n",
    "    )  # To find probability of excited state, sum the elements of the count list (sum all the ones) and normalize by the number of elements\n",
    "    probability_gnd_gnd = (\n",
    "            1 - probability_exc_gnd\n",
    "    )  # Find the probability of ground state\n",
    "\n",
    "    # Discriminate excited state data\n",
    "    count_array = list(map(int, trained_discriminator[0].discriminate(exc_data)))\n",
    "    probability_exc_exc = np.sum(count_array) / len(count_array)\n",
    "    probability_gnd_exc = 1 - probability_exc_exc\n",
    "\n",
    "    return probability_exc_gnd, probability_exc_exc, gnd_exc_data, trained_discriminator\n",
    "\n",
    "\n",
    "def rabi_experiment(\n",
    "        qubit, backend, num_shots, measurement_schedule, measurement_setting\n",
    "):\n",
    "    \"\"\"Run a Rabi experiment.\"\"\"\n",
    "    # Get qubit frequency\n",
    "    qubit = 0\n",
    "    backend.properties(refresh=True)\n",
    "    qubit_frequency_updated = backend.properties().qubit_property(qubit, \"frequency\")[0]\n",
    "\n",
    "    # Drive and measurement channels\n",
    "    inst_sched_map = backend_defaults.instruction_schedule_map\n",
    "    pi_default = inst_sched_map.get(\"x\", qubits=backend_config.meas_map[qubit])\n",
    "\n",
    "    # The minimum duration of a pulse in the armonk backend is 64*dt\n",
    "    num_time_points = 50  # Number of points in the Rabi experiment\n",
    "    pulse_amp = 0.4\n",
    "    pulse_times = np.array(\n",
    "        [\n",
    "            64\n",
    "            + np.arange(\n",
    "                0,\n",
    "                get_closest_multiple_of_16(16 * 2 * num_time_points),\n",
    "                get_closest_multiple_of_16(16 * 2),\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    rabi_schedules = []\n",
    "    for integer_duration in pulse_times[0]:\n",
    "        waveform = np.ones([integer_duration]) * pulse_amp\n",
    "        this_schedule = pulse.Schedule(name=f\"I pulse: duration = {integer_duration}\")\n",
    "        this_schedule += pulse.Play(pulse.Waveform(waveform), drive_chan)\n",
    "        this_schedule += measurement_schedule << this_schedule.duration\n",
    "        rabi_schedules.append(this_schedule)\n",
    "\n",
    "    if measurement_setting == \"calibrated\":\n",
    "        # Create two schedules\n",
    "        # Excited state schedule\n",
    "        exc_schedule = pulse.Schedule(name=\"cal_11\")\n",
    "        exc_schedule += pi_default\n",
    "        exc_schedule += measurement_schedule\n",
    "\n",
    "        # Ground state schedule\n",
    "        gnd_schedule = pulse.Schedule(name=\"cal_00\")\n",
    "        gnd_schedule += measurement_schedule\n",
    "\n",
    "        # Add calibration schedules to Rabi schedules\n",
    "        rabi_schedules = [gnd_schedule] + [exc_schedule] + rabi_schedules\n",
    "\n",
    "        # Assemble schedules in experiment\n",
    "        rabi_experiment_program = assemble(\n",
    "            rabi_schedules,\n",
    "            backend=backend,\n",
    "            meas_level=1,\n",
    "            meas_return=\"single\",\n",
    "            shots=num_shots,\n",
    "            schedule_los=[{drive_chan: qubit_frequency_updated}]\n",
    "                         * (len(pulse_times[0]) + 2),\n",
    "        )\n",
    "        # Run\n",
    "        job = backend.run(rabi_experiment_program)\n",
    "        job_monitor(job)\n",
    "        rabi_results = job.result(timeout=120)\n",
    "        return rabi_results\n",
    "\n",
    "    elif measurement_setting == \"default\":\n",
    "        # Assemble schedules in experiment\n",
    "        rabi_experiment_program = assemble(\n",
    "            rabi_schedules,\n",
    "            backend=backend,\n",
    "            meas_level=2,\n",
    "            meas_return=\"avg\",\n",
    "            shots=num_shots,\n",
    "            schedule_los=[{drive_chan: qubit_frequency_updated}]\n",
    "                         * (len(pulse_times[0])),\n",
    "        )\n",
    "\n",
    "        # Run\n",
    "        job = backend.run(rabi_experiment_program)\n",
    "        job_monitor(job)\n",
    "        rabi_results = job.result(timeout=120)\n",
    "        return rabi_results\n",
    "\n",
    "    else:\n",
    "        sys.exit(\"Select correct measurement setting: 'default' or 'calibrated' \")\n",
    "\n",
    "\n",
    "# Parameters\n",
    "GHz = 1.0e9  # Gigahertz\n",
    "MHz = 1.0e6  # Megahertz\n",
    "us = 1.0e-6  # Microseconds\n",
    "ns = 1.0e-9  # Nanoseconds\n",
    "runs = 16  # Number of runs for collecting statistics\n",
    "num_shots = 1024  # Number of times each program is repeated\n",
    "num_shots_with_training = 8 * num_shots\n",
    "test_sample_size = 0.167  # Size of sample for testing of discriminators\n",
    "num_time_points = 50  # Number of points in the Rabi experiment\n",
    "colors = {\"Calibrated\": \"#680CE9\", \"Default\": \"#000000\"}\n",
    "\n",
    "if use_IBM:\n",
    "    # IBM-Q imports\n",
    "    import qiskit.pulse as pulse\n",
    "    import qiskit.pulse.pulse_lib as pulse_lib\n",
    "    from qiskit import IBMQ\n",
    "    from qiskit.compiler import assemble\n",
    "    from qiskit.tools.jupyter import *\n",
    "    from qiskit.tools.monitor import job_monitor\n",
    "\n",
    "    # IBM credentials and backend selection\n",
    "    IBMQ.enable_account(\"YOUR TOKEN HERE\")\n",
    "    provider = IBMQ.get_provider(hub=\"ibm-q\", group=\"open\", project=\"main\")\n",
    "    backend = provider.get_backend(\"ibmq_armonk\")\n",
    "    backend_defaults = backend.defaults()\n",
    "    backend_config = backend.configuration()\n",
    "    assert backend_config.open_pulse, \"Backend doesn't support OpenPulse\"\n",
    "\n",
    "    # Backend properties\n",
    "    qubit = 0\n",
    "    qubit_freq_est = backend_defaults.qubit_freq_est[qubit]\n",
    "    dt = backend_config.dt\n",
    "    print(f\"Qubit: {qubit}\")\n",
    "    print(f\"Hardware sampling time: {dt/ns} ns\")\n",
    "    print(f\"Qubit frequency estimate: {qubit_freq_est/GHz} GHz\")\n",
    "\n",
    "    # Set command channels\n",
    "    drive_chan = pulse.DriveChannel(qubit)\n",
    "\n",
    "    # Set measurement channels\n",
    "    meas_chan = pulse.MeasureChannel(qubit)\n",
    "    acq_chan = pulse.AcquireChannel(qubit)\n",
    "\n",
    "    # Measurement map\n",
    "    meas_map_idx = None\n",
    "    for i, measure_group in enumerate(backend_config.meas_map):\n",
    "        if qubit in measure_group:\n",
    "            meas_map_idx = i\n",
    "            break\n",
    "    assert meas_map_idx is not None, f\"Couldn't find qubit {qubit} in the meas_map!\"\n",
    "\n",
    "else:\n",
    "    qubit = 0\n",
    "    dt = 2 / 9 * ns\n",
    "\n",
    "# IBM-Q auxiliary functions\n",
    "def get_closest_multiple_of_16(num):\n",
    "    return int(num + 8) - (int(num + 8) % 16)\n",
    "\n",
    "\n",
    "def fit_function(x_values, y_values, function, init_params):\n",
    "    fitparams, conv = curve_fit(function, x_values, y_values, init_params)\n",
    "    y_fit = function(x_values, *fitparams)\n",
    "    return fitparams, y_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if use_IBM:\n",
    "    # Use default measurement settings\n",
    "    inst_sched_map = backend_defaults.instruction_schedule_map\n",
    "    default_measure_schedule = inst_sched_map.get(\n",
    "        \"measure\", qubits=backend_config.meas_map[meas_map_idx]\n",
    "    )\n",
    "\n",
    "    # Run experiment\n",
    "    gnd_exc_experiment_result = ground_excited_experiment(\n",
    "        qubit, backend, num_shots, default_measure_schedule\n",
    "    )\n",
    "\n",
    "    # Save data\n",
    "    filename = \"gnd_exc_experiment_result\" + timestr\n",
    "    outfile = open(filename, \"wb\")\n",
    "    pickle.dump(gnd_exc_experiment_result, outfile)\n",
    "    outfile.close()\n",
    "else:\n",
    "    # Load data\n",
    "    filename = data_folder / \"gnd_exc_experiment_result\"\n",
    "    infile = open(filename, \"rb\")\n",
    "    gnd_exc_experiment_result = pickle.load(infile)\n",
    "    infile.close()\n",
    "\n",
    "# Discriminator used to classify data\n",
    "discriminator_list = [\n",
    "    create_random_forest_discriminator,\n",
    "    create_gradient_boosting_discriminator,\n",
    "    create_linear_discriminator,\n",
    "]\n",
    "\n",
    "discriminators = []\n",
    "\n",
    "# Classify data\n",
    "for disc in discriminator_list:\n",
    "    discriminators.append(disc(gnd_exc_experiment_result, [qubit], [\"0\", \"1\"]))\n",
    "\n",
    "# Plot result of the classification\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle(\"Discriminators\", y=1)\n",
    "titles = [\"RandomForest\", \"Gradient boosting\", \"Linear\"]\n",
    "for idx, disc in enumerate(discriminators):\n",
    "    ax = axs[idx]\n",
    "    ax.set_title(titles[idx])\n",
    "    plot_discriminator(\n",
    "        disc, ax, flag_misclassified=True, show_boundary=True, title=False\n",
    "    )\n",
    "    if idx != 0:\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.set_ylabel(\"\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if use_IBM:\n",
    "    # Parameters for amplitude scan\n",
    "    measurement_amp_min = 0.05\n",
    "    measurement_amp_max = 1\n",
    "    measurement_amp_steps = 10\n",
    "    measurement_amp_array = np.linspace(\n",
    "        measurement_amp_min, measurement_amp_max, measurement_amp_steps\n",
    "    )\n",
    "\n",
    "    # Parameters for duration scan\n",
    "    measurement_samples_min = 1\n",
    "    measurement_samples_max = 4\n",
    "    measurement_samples_steps = 15\n",
    "    measurement_samples_array = np.linspace(\n",
    "        measurement_samples_min, measurement_samples_max, measurement_samples_steps\n",
    "    )\n",
    "\n",
    "    measurement_data = []\n",
    "    silhouette_list = []\n",
    "\n",
    "    # Iterate over amplitude values\n",
    "    for measurement_amp in measurement_amp_array:\n",
    "        print(\"\\nAMPLITUDE:\", measurement_amp, \" a.u.\")\n",
    "\n",
    "        silhouette_time_list = []\n",
    "        # Iterate over duration values\n",
    "        for measurement_samples_us in measurement_samples_array:\n",
    "            ### Construct the measurement pulse\n",
    "            # Measurement pulse parameters\n",
    "            measurement_sigma_us = (\n",
    "                0.5  # Width of the gaussian part of the rise and fall in us\n",
    "            )\n",
    "            measurement_risefall_us = 0.1  # Truncating parameter: how many samples to dedicate to the risefall\n",
    "\n",
    "            # Convert to machine format\n",
    "            measurement_sigma = get_closest_multiple_of_16(\n",
    "                measurement_sigma_us * 1e-6 / dt\n",
    "            )\n",
    "            measurement_risefall = get_closest_multiple_of_16(\n",
    "                measurement_risefall_us * 1e-6 / dt\n",
    "            )\n",
    "            measurement_samples = get_closest_multiple_of_16(\n",
    "                measurement_samples_us * 1e-6 / dt\n",
    "            )\n",
    "            print(\"DURATION:\", measurement_samples_us, \" a.u.\")\n",
    "\n",
    "            # Define measurement pulse\n",
    "            measurement_pulse = pulse_lib.gaussian_square(\n",
    "                duration=measurement_samples,\n",
    "                sigma=measurement_sigma,\n",
    "                amp=measurement_amp,\n",
    "                risefall=measurement_risefall,\n",
    "                name=\"measurement_pulse\",\n",
    "            )\n",
    "\n",
    "            # Import backend configurations\n",
    "            backend_config = backend.configuration()\n",
    "\n",
    "            # Set measurement channels\n",
    "            meas_chan = pulse.MeasureChannel(qubit)\n",
    "            acq_chan = pulse.AcquireChannel(qubit)\n",
    "\n",
    "            # Add a measurement stimulus on the measure channel pulse to trigger readout\n",
    "            measure_schedule = pulse.Play(measurement_pulse, meas_chan)\n",
    "\n",
    "            # Trigger data acquisition, and store measured values into respective memory slots\n",
    "            measure_schedule += pulse.Acquire(\n",
    "                measurement_pulse.duration,\n",
    "                pulse.AcquireChannel(backend_config.meas_map[meas_map_idx][0]),\n",
    "                pulse.MemorySlot(backend_config.meas_map[meas_map_idx][0]),\n",
    "            )\n",
    "\n",
    "            # Run 0-1 state discrimination experiment\n",
    "            gnd_exc_experiment_result = ground_excited_experiment(\n",
    "                qubit, backend, num_shots_with_training, measure_schedule\n",
    "            )\n",
    "\n",
    "            # Train and classify data with Boulder Opal's discriminator\n",
    "            gnd_exc_results = train_discriminator(\n",
    "                gnd_exc_experiment_result, test_sample_size\n",
    "            )[2]\n",
    "\n",
    "            # Store results\n",
    "            measurement_data.append(gnd_exc_results)\n",
    "            silhouette_time_list.append(intercluster_distance(gnd_exc_results))\n",
    "\n",
    "        silhouette_list.append(silhouette_time_list)\n",
    "\n",
    "    # Save data\n",
    "    filename = \"measurement_amplitude_array\" + timestr\n",
    "    outfile = open(filename, \"wb\")\n",
    "    pickle.dump(measurement_amp_array, outfile)\n",
    "    outfile.close()\n",
    "    filename = \"measurement_samples_array\" + timestr\n",
    "    outfile = open(filename, \"wb\")\n",
    "    pickle.dump(measurement_samples_array, outfile)\n",
    "    outfile.close()\n",
    "    filename = \"measurements\" + timestr\n",
    "    outfile = open(filename, \"wb\")\n",
    "    pickle.dump(measurement_data, outfile)\n",
    "    outfile.close()\n",
    "    filename = \"silhouette_list\" + timestr\n",
    "    outfile = open(filename, \"wb\")\n",
    "    pickle.dump(silhouette_list, outfile)\n",
    "    outfile.close()\n",
    "else:\n",
    "    # Load data\n",
    "    filename = data_folder / \"measurement_amplitude_array\"\n",
    "    infile = open(filename, \"rb\")\n",
    "    measurement_amp_array = pickle.load(infile)\n",
    "    infile.close()\n",
    "    filename = data_folder / \"measurement_samples_array\"\n",
    "    infile = open(filename, \"rb\")\n",
    "    measurement_samples_array = pickle.load(infile)\n",
    "    infile.close()\n",
    "    filename = data_folder / \"measurements\"\n",
    "    infile = open(filename, \"rb\")\n",
    "    measurement_data = pickle.load(infile)\n",
    "    infile.close()\n",
    "    filename = data_folder / \"silhouette_list\"\n",
    "    infile = open(filename, \"rb\")\n",
    "    silhouette_list = pickle.load(infile)\n",
    "    infile.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_scores_example = []\n",
    "discriminated_data = []\n",
    "idx_measurements = [40, 70, 143]  # Example of measurement results\n",
    "\n",
    "for idx_measurement in idx_measurements:\n",
    "    # Find silhouette score of a given measurement data\n",
    "    x_idx = int(idx_measurement % len(measurement_samples_array))\n",
    "    y_idx = int(idx_measurement / len(measurement_samples_array))\n",
    "\n",
    "    # Make Result object from measurement data\n",
    "    silhouette_score_result = copy.deepcopy(gnd_exc_experiment_result)\n",
    "    data_idx = int(len(gnd_exc_experiment_result.results[0].data.memory))\n",
    "    exc_data_idx = int(len(measurement_data[idx_measurement]) / 2)\n",
    "    silhouette_score_result.results[0].data.memory = [\n",
    "        [sample] for sample in (measurement_data[idx_measurement][:data_idx]).tolist()\n",
    "    ]\n",
    "    silhouette_score_result.results[1].data.memory = [\n",
    "        [sample]\n",
    "        for sample in (\n",
    "            measurement_data[idx_measurement][exc_data_idx : exc_data_idx + data_idx]\n",
    "        ).tolist()\n",
    "    ]\n",
    "\n",
    "    # Classify data\n",
    "    discriminated_data.append(\n",
    "        create_gradient_boosting_discriminator(\n",
    "            silhouette_score_result, [qubit], [\"0\", \"1\"]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Get silhouette score\n",
    "    silhouette_scores_example.append(round(silhouette_list[y_idx][x_idx], 3))\n",
    "\n",
    "# Plot result of the classification\n",
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.suptitle(\"Discriminator performance\", y=1)\n",
    "for idx, data in enumerate(discriminated_data):\n",
    "    ax = axs[idx]\n",
    "    plot_discriminator(\n",
    "        data, ax, flag_misclassified=True, show_boundary=True, title=False\n",
    "    )\n",
    "    if idx != 0:\n",
    "        ax.yaxis.set_ticklabels([])\n",
    "        ax.set_ylabel(\"\")\n",
    "    ax.set_title(f\"Silhouette score: {silhouette_scores_example[idx]}\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate all measurements to determine which gives the best silhoutte score\n",
    "gnd_exc_data, idx = (\n",
    "    get_best_measurement(measurement_data)[\"measurement\"],\n",
    "    get_best_measurement(measurement_data)[\"index\"],\n",
    ")\n",
    "\n",
    "# Find duration and amplitude of best measurement results\n",
    "dur_idx = int(idx % len(measurement_samples_array))\n",
    "amp_idx = int(idx / len(measurement_samples_array))\n",
    "\n",
    "measurement_duration = measurement_samples_array[dur_idx]\n",
    "measurement_amp = measurement_amp_array[amp_idx]\n",
    "\n",
    "print(\"Best duration: \", measurement_duration)\n",
    "print(\"Best amplitude: \", measurement_amp)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot landscape of probability of excited state\n",
    "fig, ax = plt.subplots(figsize=(10, 5), constrained_layout=True)\n",
    "\n",
    "Y = measurement_amp_array\n",
    "X = measurement_samples_array\n",
    "X, Y = np.meshgrid(X, Y)\n",
    "Z0 = silhouette_list\n",
    "\n",
    "cs = ax.contourf(\n",
    "    X,\n",
    "    Y,\n",
    "    Z0,\n",
    "    len(measurement_amp_array) * len(measurement_samples_array),\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=0.5,\n",
    "    vmax=0.8,\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Silhouette score\")\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "ax.set_xlabel(\"Time (Âµs)\")\n",
    "\n",
    "cb_ax = fig.add_axes([1.02, 0.12, 0.02, 0.8])\n",
    "cbar1 = fig.colorbar(cs, cax=cb_ax, orientation=\"vertical\")\n",
    "\n",
    "# Mark the value of the default setting and the best value from the scan\n",
    "if use_IBM:\n",
    "    backend_defaults = backend.defaults()\n",
    "    backend_config = backend.configuration()\n",
    "    inst_sched_map = backend_defaults.instruction_schedule_map\n",
    "    default_measure_schedule = inst_sched_map.get(\n",
    "        \"measure\", qubits=backend_config.meas_map[meas_map_idx]\n",
    "    )  # measurement pulse parameters for default measurement\n",
    "    default_amplitude = np.real(default_measure_schedule.instructions[1][1].pulse.amp)\n",
    "    default_duration = default_measure_schedule.duration * dt / us\n",
    "else:\n",
    "    default_amplitude = 0.605\n",
    "    default_duration = 3.556\n",
    "\n",
    "ax.autoscale(False)  # Avoid scatterplot changing the plot limits\n",
    "ax.scatter(\n",
    "    default_duration,\n",
    "    default_amplitude,\n",
    "    color=colors[\"Default\"],\n",
    "    marker=\"X\",\n",
    "    s=200,\n",
    "    zorder=1,\n",
    "    label=\"Default\",\n",
    ")\n",
    "ax.scatter(\n",
    "    measurement_duration,\n",
    "    measurement_amp,\n",
    "    color=colors[\"Calibrated\"],\n",
    "    marker=\"X\",\n",
    "    s=200,\n",
    "    zorder=1,\n",
    "    label=\"Best silhouette\",\n",
    ")\n",
    "ax.legend(loc=\"lower left\")\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}